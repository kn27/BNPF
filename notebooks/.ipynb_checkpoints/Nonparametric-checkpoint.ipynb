{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T06:51:00.777339Z",
     "start_time": "2019-12-14T06:51:00.348338Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T06:51:11.812337Z",
     "start_time": "2019-12-14T06:51:00.783337Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from numpy import random\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "import json\n",
    "import scipy\n",
    "import copy \n",
    "import scipy.sparse as sparse\n",
    "from scipy.special import digamma\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T06:51:12.442338Z",
     "start_time": "2019-12-14T06:51:11.846336Z"
    }
   },
   "outputs": [],
   "source": [
    "from matrix_factorization import read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T06:51:12.972342Z",
     "start_time": "2019-12-14T06:51:12.450337Z"
    }
   },
   "outputs": [],
   "source": [
    "from nonparametric import simulate, NPNMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T06:51:31.398342Z",
     "start_time": "2019-12-14T06:51:27.696347Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of nonparametric failed: Traceback (most recent call last):\n",
      "  File \"/home/keane/anaconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 244, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/keane/anaconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 378, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/keane/anaconda3/lib/python3.7/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/keane/anaconda3/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 630, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 724, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 860, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 791, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/keane/git/FOGM/nonparametric.py\", line 326\n",
      "    def online_inference(self, est_total=None):\n",
      "                                              ^\n",
      "IndentationError: unindent does not match any outer indentation level\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "X, theta, beta, s, v = simulate(U = 2000,\n",
    "    D = 2000,\n",
    "    K = 20,\n",
    "    alpha=1.1,\n",
    "    beta_shape_prior=0.3,\n",
    "    beta_rate_prior=0.3,\n",
    "    s_rate_prior=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T06:51:34.800342Z",
     "start_time": "2019-12-14T06:51:33.341340Z"
    }
   },
   "outputs": [],
   "source": [
    "X = scipy.sparse.csr_matrix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T09:06:43.792768Z",
     "start_time": "2019-12-14T09:06:40.619767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using fixed seed 0\n"
     ]
    }
   ],
   "source": [
    "nmf = NPNMF(X ,T = 100, seed = 0, threshold = 1e-5, max_iter = 20)\n",
    "#nmf.ELBO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logjoint:-3221348.0509240003\n",
      "Iter 1: logjoint = -3221348.0509240003, last_logjoint = 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5832b5b814a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/git/FOGM/nonparametric.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;31m#Update across item\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#q(beta_d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m             \u001b[0mt4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;31m#print(f'Iter {_iter}: Update items = {t4 - t3}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/FOGM/nonparametric.py\u001b[0m in \u001b[0;36mupdate_items\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_beta_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_shape_prior\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_phi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_beta_rate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_rate_prior\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0methetasum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_beta_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_beta_shape\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_beta_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/FOGM/nonparametric.py\u001b[0m in \u001b[0;36methetasum\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0methetasum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_s_mean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logpi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mebetasum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/FOGM/nonparametric.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0methetasum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_s_mean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logpi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mebetasum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nmf.inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf.max_iter = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if stick breaking is working!\n",
    "plt.plot(nmf._v.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.array([[nmf._s_shape[u]/nmf._s_rate[u] * nmf._v[u,k] *np.prod(1-nmf._v[u,:k]) for k in range(nmf.T)] for u in range(nmf.U)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = nmf._beta_shape/nmf._beta_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poisson_mean = theta @ beta.T\n",
    "poisson_mean[X.toarray() == 0] = 0\n",
    "simulated = np.random.poisson(poisson_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#posterior check\n",
    "\n",
    "ax = sns.distplot(np.sum(X,0),hist=True, kde=True)\n",
    "sns.distplot(np.sum(simulated,0),hist=True, kde=True)\n",
    "ax.set_title('Distribution of users by total rating')\n",
    "ax.set(xlabel='Total rating per user')\n",
    "ax.legend(['Observed Data', 'Simulated from fitted model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#posterior check\n",
    "\n",
    "ax = sns.distplot(np.sum(X,0),hist=True, kde=True)\n",
    "sns.distplot(np.sum(simulated,0),hist=True, kde=True)\n",
    "ax.set_title('Distribution of users by total rating')\n",
    "ax.set(xlabel='Total rating per user')\n",
    "ax.legend(['Observed Data', 'Simulated from fitted model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#posterior check\n",
    "\n",
    "ax = sns.distplot(np.sum(X,1),hist=True, kde=True)\n",
    "sns.distplot(np.sum(simulated,1),hist=True, kde=True)\n",
    "ax.set_title('Distribution of users by total rating')\n",
    "ax.set(xlabel='Total rating per user')\n",
    "ax.legend(['Observed Data', 'Simulated from fitted model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#posterior check\n",
    "\n",
    "ax = sns.distplot(np.sum(X,1),hist=True, kde=True)\n",
    "sns.distplot(np.sum(simulated,1),hist=True, kde=True)\n",
    "ax.set_title('Distribution of users by total rating')\n",
    "ax.set(xlabel='Total rating per user')\n",
    "ax.legend(['Observed Data', 'Simulated from fitted model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#posterior check\n",
    "\n",
    "ax = sns.distplot(np.sum(X,1),hist=True, kde=True)\n",
    "sns.distplot(np.sum(simulated,1),hist=True, kde=True)\n",
    "ax.set_title('Distribution of users by total rating')\n",
    "ax.set(xlabel='Total rating per user')\n",
    "ax.legend(['Observed Data', 'Simulated from fitted model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [np.sum([nmf.X[u,d] * (1 - np.sum(nmf._phi[u,d,:])) for d in range(nmf.D)]) for u in range(nmf.U)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nmf.inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A,B,C = nmf.get_ABC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.min(), A.max(), B.min(), B.max(), C.min(),C.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(A == A.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(B == B.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf.u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf.load_model('model_1.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nmf._phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([1,2,3])[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf._v.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf.save_model(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf.load_model('model_1.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf.inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf.X[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf.X.tocsc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time0 = time.time()\n",
    "for i in range(3000):\n",
    "    nmf.X[:,np.random.rand(100)]\n",
    "time.time() - time0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time0 = time.time()\n",
    "for i in range(3000):\n",
    "    nmf.X.tocsc()[np.random.rand(100),:]\n",
    "time.time() - time0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time0 = time.time()\n",
    "for i in range(3000):\n",
    "    nmf.X.tocsc()[:,np.random.rand(100)]\n",
    "time.time() - time0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time0 = time.time()\n",
    "for i in range(3000):\n",
    "    nmf.X[np.random.rand(100),:]\n",
    "time.time() - time0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nmf.inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nmf.byuser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in range(nmf.U):\n",
    "    for k in range(nmf.T):\n",
    "        try:\n",
    "            nmf.solve_quadratic(A[u,k], B[u,k], C[u,k])\n",
    "        except:\n",
    "            print(u,k)\n",
    "            pass\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf._s_rate[147]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(nmf._beta_shape[:,0]/nmf._beta_rate[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(10,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = 147\n",
    "k = 0\n",
    "l = 0\n",
    "[nmf._v[u,l] * np.prod(1-nmf._v[u,:l])/(1-nmf._v[u,k]) * np.sum(nmf._beta_shape[:,l]/ nmf._beta_rate[:,l]) for l in range(k+1,nmf.T)]\n",
    "#- np.prod(1-nmf._v[u,:k]) * np.sum(nmf._beta_shape[:,k]/nmf._beta_rate[:,k]) \\\n",
    "#+ nmf.D * nmf.beta_shape_prior/nmf.beta_rate_prior * np.prod(1-nmf._v[u,:]) / nmf._v[u,k]        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A[147,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B[147,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C[147,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A,B,C = nmf.get_ABC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(-np.sqrt(B**2 - 4*A*C) - B) / A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(-np.sqrt(B**2 - 4*A*C) - B) / A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf.inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "46318/46350-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 1.807934296800437e-10\n",
    "B = 1.0004423587287066\n",
    "C=  -0.00041595806984341416\n",
    "(-B + np.sqrt(B**2 - 4*A*C)) / (2 * A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from multiprocess import Pool\n",
    "def f(x,y): return x*y\n",
    "p = Pool(4)\n",
    "result = p.map(f, [(1,2), (3,4)])\n",
    "print(result.get(timeout=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = copy.deepcopy(nmf._phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nmf.inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf.solve_quadratic(A= 2.5972095342520613e-16, B=2.052183719154443, C= -1.0518572257929042)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 0.00000000000001\n",
    "B=2.052183719154443\n",
    "C= -1.0518572257929042"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(-B + np.sqrt(B**2 - 4*A*C)) / (2 * A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T09:07:02.761769Z",
     "start_time": "2019-12-14T09:06:43.802767Z"
    }
   },
   "outputs": [],
   "source": [
    "nmf.update_phi()\n",
    "nmf.ELBO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T09:07:27.838772Z",
     "start_time": "2019-12-14T09:07:02.764769Z"
    }
   },
   "outputs": [],
   "source": [
    "nmf.update_items()\n",
    "nmf.ELBO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T08:52:32.970868Z",
     "start_time": "2019-12-14T08:52:28.068868Z"
    }
   },
   "outputs": [],
   "source": [
    "nmf.update_sticks_scalars()\n",
    "nmf.ELBO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T06:54:10.149944Z",
     "start_time": "2019-12-14T06:54:05.236943Z"
    }
   },
   "outputs": [],
   "source": [
    "nmf.update_sticks()\n",
    "nmf.ELBO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T21:19:42.215722Z",
     "start_time": "2019-12-13T21:19:41.861723Z"
    }
   },
   "outputs": [],
   "source": [
    "np.savez('test.npz', a = a, b = a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T21:19:43.366724Z",
     "start_time": "2019-12-13T21:19:42.838723Z"
    }
   },
   "outputs": [],
   "source": [
    "test = np.load('test.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T21:19:46.065732Z",
     "start_time": "2019-12-13T21:19:45.718725Z"
    }
   },
   "outputs": [],
   "source": [
    "test['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T21:03:06.087239Z",
     "start_time": "2019-12-13T21:03:05.434238Z"
    }
   },
   "outputs": [],
   "source": [
    "nmf._phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T19:56:25.027135Z",
     "start_time": "2019-12-13T19:56:24.296136Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#unit test\n",
    "def \n",
    "def test:\n",
    "    [nmf._phi[u,d,:].sum() for u,d in nmf.nonzero]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T04:00:25.658080Z",
     "start_time": "2019-12-12T04:00:25.503059Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate(theta,beta,rating_valid):\n",
    "    size = len(list(zip(*rating_valid.nonzero())))\n",
    "    rating_valid = rating_valid.toarray().flatten()\n",
    "    mu = (theta @ beta.T).flatten()\n",
    "    mu = mu[rating_valid > 0]\n",
    "    rating_valid = rating_valid[rating_valid > 0]\n",
    "    mu[mu>10] = 10\n",
    "    assert mu.shape == rating_valid.shape, f'{mu.shape} vs {rating_valid.shape}'\n",
    "    return (np.sum(rating_valid * np.log(mu)) - np.sum(mu))/size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variational Inference for Nonparametrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T04:00:25.884077Z",
     "start_time": "2019-12-12T04:00:25.662061Z"
    }
   },
   "outputs": [],
   "source": [
    "rating_train, rating_valid, rating_train, _ = read('./data/movielens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T04:00:26.042060Z",
     "start_time": "2019-12-12T04:00:25.886061Z"
    }
   },
   "outputs": [],
   "source": [
    "kwargs = {'T': 50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T04:00:26.245059Z",
     "start_time": "2019-12-12T04:00:26.046061Z"
    }
   },
   "outputs": [],
   "source": [
    "#NOTE: To be wrapped in def vi(rating_train, rating_valid, **kwargs):\n",
    "\n",
    "#Use sparse matrix representation\n",
    "U,D = rating_train.shape\n",
    "indices = rating_train.indices\n",
    "indptr = rating_train.indptr\n",
    "nonzero = list(zip(*rating_train.nonzero()))\n",
    "byrow = {row:[indices[i] for i in range(indptr[row], indptr[row+1])] for row in range(U)}\n",
    "\n",
    "rating_csc = rating_train.tocsc()\n",
    "indices = rating_csc.indices\n",
    "indptr = rating_csc.indptr\n",
    "bycol = {col:[indices[i] for i in range(indptr[col], indptr[col+1])] for col in range(D)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joint distribution:\n",
    "$$p(z, \\beta, s, v| \\alpha, c, a,b) = \\prod_{u=1}^{U} p(s_u | \\alpha, c) \\prod_{k=1}^{\\infty} \\prod_{u=1}^{U} p(v_{uk} | \\alpha)   \\prod_{k=1}^{\\infty} \\prod_{d=1}^{D} p(\\beta_{dk} | a, b) \\prod_{k=1}^{\\infty} \\prod_{u=1}^N \\prod_{d=1}^D p(z_{udk} | \\theta_{uk}, \\beta_{dk})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the stick proportions:\n",
    "$$\\theta_{uk} = s_u v_{uk} \\prod_{i=1}^{k-1}(1-v_{ui})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variational Inference:\n",
    "\n",
    "$q(s_u) = \\text{Gamma}(s_u | \\omega_{u,0}, \\omega_{u,1})$\n",
    "\n",
    "$q(v_{uk}) = \\zeta_{\\tau_{uk}}(v_{uk}) \\text{ for } k \\leq T, p(v_{uk}) \\text{ for } k \\geq T + 1$\n",
    "\n",
    "$q(\\beta_{dk}) = \\text{Gamma}(\\beta_{dk} | \\lambda_{ik,0}, \\lambda_{dk, 1}) \\text { for } k \\leq T, p(\\beta_{dk}) \\text{ for } k \\geq T+1$\n",
    "\n",
    "$q(z_{ud}) = \\text{Mult}(z_{ud} | y_{ud}, \\phi_{ud})$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T04:00:39.098120Z",
     "start_time": "2019-12-12T04:00:38.948120Z"
    }
   },
   "outputs": [],
   "source": [
    "#Starting values\n",
    "I = 300\n",
    "T = kwargs.pop('T', 50) #Truncate level\n",
    "alpha = kwargs.pop('alpha', 0.01)\n",
    "omega_rate = np.array([0.3]*U) \n",
    "omega_shape = np.array([1]*U)\n",
    "lambda_rate = np.array([[0.3]*T]*U) \n",
    "lambda_shape = np.array([[1]*T]*U)\n",
    "tau = np.random.beta(1, alpha, size = T)\n",
    "phi = np.zeros((len(nonzero),I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NPNMF:\n",
    "    def __init__(self, X, K=512, seed=None, **kwargs):\n",
    "        '''\n",
    "        BN = LVI_BP_NMF(X, K=512, smoothness=100, seed=None, alpha=2.,\n",
    "                        a0=1., b0=1., c0=1e-6, d0=1e-6)\n",
    "        Required arguments:\n",
    "            X:              U-by-D nonnegative matrix (numpy.ndarray)\n",
    "                            the data to be factorized\n",
    "                            Assume scipy sparse matrix format\n",
    "        Optional arguments:\n",
    "            K:              the size of the initial dictionary\n",
    "                            will be truncated to a proper size\n",
    "            seed:           the random seed to control the random\n",
    "                            initialization\n",
    "                            **variational inference can only converge to local\n",
    "                            optimum, thus try different seeds**\n",
    "            alpha:          hyperparameter for activation.\n",
    "            a0, b0:         both must be specified\n",
    "                            hyperparameters for sparsity\n",
    "            c0, d0:         both must be specified\n",
    "                            hyperparameters for Gaussian noise\n",
    "        '''\n",
    "        self.X = X.copy()\n",
    "        self.U, self.D = self.X.shape\n",
    "        self.T = T\n",
    "        \n",
    "        #Working with sparse matrix\n",
    "        indices = X.indices\n",
    "        indptr = X.indptr\n",
    "        self.nonzero = list(zip(*X.nonzero()))\n",
    "        self.byuser = {row:[indices[i] for i in range(indptr[row], indptr[row+1])] for row in range(U)\n",
    "        \n",
    "        self.rating_csc = X.tocsc()\n",
    "        indices = X.indices\n",
    "        indptr = X.indptr\n",
    "        self.byitem = {col:[indices[i] for i in range(indptr[col], indptr[col+1])] for col in range(D)}\n",
    "\n",
    "        self._parse_args(**kwargs)\n",
    "        if seed is None:\n",
    "            print 'Using random seed'\n",
    "            np.random.seed()\n",
    "        else:\n",
    "            print 'Using fixed seed {}'.format(seed)\n",
    "            np.random.seed(seed)\n",
    "        self._init()\n",
    "\n",
    "    def _parse_args(self, **kwargs):\n",
    "        '''\n",
    "        Parse the hyperparameters\n",
    "        '''\n",
    "        self.alpha = float(kwargs.get('alpha', 2.))\n",
    "        self.beta_shape_prior = float(kwargs.get('beta_shape_prior', 1.)) #a\n",
    "        self.beta_rate_prior = float(kwargs.get('beta_rate_prior', 1.))   #b          \n",
    "        self.s_rate_prior = float(kwargs.get('s_rate_prior', 1e-6))       #c\n",
    "        \n",
    "    def initialize(self):\n",
    "        # variational parameters for Beta \n",
    "        self._beta_shape = np.full((self.D, self.T), 0.3)\n",
    "        self._beta_rate = np.full((self.D, self.T), 0.3)\n",
    "        \n",
    "        # variational parameters S \n",
    "        self._s_shape = np.full(self.U, 0.3)\n",
    "        self._s_rate = np.full(self.U, 0.3)\n",
    "        \n",
    "        # variational parameters for Z\n",
    "        self.phi = np.zeros(len(self.nonzero), T)\n",
    "                       \n",
    "    def update_phi(self):\n",
    "        for i,ud in enumerate(nonzero):\n",
    "            u,d = ud\n",
    "            elogbeta = [digamma(self._beta_shape[d][k]) - log(self._beta_rate[d][k]) for k in range(self.T)]\n",
    "            elogs = digamma(self._s_shape[u]) - log(self._s_rate[u])\n",
    "            phi = [(elogbeta + elogs + self._logpi[u][k]) for k in range(_k)] \n",
    "            phi = np.array([phi, self.compute_mult_normalizer_infsum(u)])\n",
    "            logsum = s.logsum();\n",
    "            phi.lognormalize(logsum)\n",
    "            self.phi = phi\n",
    "    \n",
    "    def _logpi(self,u,k):\n",
    "        return exp(lpid[u][_k-1] - log(vd[u][_k-1]) + log(1 - vd[u][_k-1]))\n",
    "                       \n",
    "    def elogtheta_at_truncation(self, u):\n",
    "        elogsu = digamma(self._s_shape[u]) - log(self._s_rate[u])\n",
    "        elogvt = digamma(1) - digamma(1+self._alpha)\n",
    "        return elogsu + elogvt + self._logpi[u][_k-1] - log(self._v[u][_k-1]) /\n",
    "                       + log(1 - self._v[u][_k-1]) #verify this\n",
    "\n",
    "    def compute_mult_normalizer_infsum(self, u,d, k):\n",
    "        elogv_t = digamma(self._alpha) - digamma(1+self._alpha)\n",
    "        return self.elogtheta_at_truncation(u) + digamma(self._beta_shape_prior) - log(self._beta_rate_prior)/\n",
    "                       - log(1 - exp(elogv_t))\n",
    "\n",
    "                       \n",
    "    def update_sticks_scalars(self):\n",
    "         for u in range(U):\n",
    "                gamma_shape[u,:] = a1 + rating_train[u,:] @ phi[u,:,:]\n",
    "                for k in range(K):\n",
    "                    gamma_rate[u,k] = kappa_shape/kappa_rate[u] + np.sum([lambda_shape[d,k]/lambda_rate[d,k] for d in byrow[u]])\n",
    "                kappa_rate[u] = a0/b0 + np.sum([gamma_shape[u,k]/gamma_rate[u,k] for k in range(K)])\n",
    "\n",
    "    def update_sticks(self):\n",
    "       \n",
    "    def update_items(self):\n",
    "        for d in range(D):\n",
    "                lambda_shape[d,:] = m1 + rating_train[:,d].T @ phi[:,d,:]\n",
    "                for k in range(K):\n",
    "                    lambda_rate[d,k] = tau_shape/tau_rate[d] + np.sum([gamma_shape[u,k]/gamma_rate[u,k] for u in bycol[d]])\n",
    "                tau_rate[d] = m0/n0 + np.sum([lambda_shape[d,k]/lambda_rate[d,k] for k in range(K)])\n",
    "\n",
    "    def validate(self):\n",
    "        self.validate()\n",
    "        theta, beta = gamma_shape/gamma_rate, lambda_shape/lambda_rate\n",
    "        training_likelihood = validate(theta, beta, rating_train)\n",
    "        val_likelihood = validate(theta, beta, rating_valid)\n",
    "        print(f'Iter {n_iter}: training_error = {training_likelihood}, val_error = {val_likelihood}, max_pref = {np.sum(theta,0).max()}, min_pref = {np.sum(theta,0).min()},max_att = {np.sum(beta,0).max()}, min_att = {np.sum(beta,0).min()}')\n",
    "        if n_iter > 0:\n",
    "            if abs(val_likelihood/last_val_likelihood-1) < threshold or n_iter >= max_iter:\n",
    "                print(f'Compete after {n_iter} iterations: Validation Error = {val_likelihood}')\n",
    "                break\n",
    "        last_val_likelihood = val_likelihood\n",
    "        n_iter += 1\n",
    "                       \n",
    "    def inference(self):\n",
    "        self.initialize()\n",
    "        while True:\n",
    "            #Update phi\n",
    "            self.update_phi()\n",
    "            \n",
    "            #Update across user\n",
    "            self.update_sticks_scalars()\n",
    "            self.update_sticks()\n",
    "            \n",
    "            #Update across item\n",
    "            self.update_items()\n",
    "            \n",
    "            #Validate\n",
    "            self.validate()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T04:48:33.743717Z",
     "start_time": "2019-12-10T04:48:33.502722Z"
    }
   },
   "outputs": [],
   "source": [
    "#CAVI\n",
    "max_iter = kwargs.pop('max_iter', 10)\n",
    "threshold = kwargs.pop('threshold', 10e-4)\n",
    "\n",
    "n_iter = 0 \n",
    "while True:\n",
    "    #For each user and item pair, update phi\n",
    "    time0 = time.time()\n",
    "    for i,ud in enumerate(nonzero):\n",
    "        u,d = ud\n",
    "        phi[i,:] = np.exp([scipy.special.digamma(gamma_shape[u,k]) - np.log(gamma_rate[u,k]) \\\n",
    "                + scipy.special.digamma(lambda_shape[d,k]) - np.log(lambda_rate[d,k]) \\\n",
    "                    for k in range(K)])\n",
    "        phi[i,:] = phi[i,:] / normalizer\n",
    "\n",
    "    #Update gamma and kappa\n",
    "    time1 = time.time()\n",
    "    for u in range(U):\n",
    "        gamma_shape[u,:] = a1 + rating_train[u,:] @ phi[u,:,:]\n",
    "        for k in range(K):\n",
    "            gamma_rate[u,k] = kappa_shape/kappa_rate[u] + np.sum([lambda_shape[d,k]/lambda_rate[d,k] for d in byrow[u]])\n",
    "        kappa_rate[u] = a0/b0 + np.sum([gamma_shape[u,k]/gamma_rate[u,k] for k in range(K)])\n",
    "\n",
    "    #Update lambda and tau\n",
    "    time2 = time.time()\n",
    "    for d in range(D):\n",
    "        lambda_shape[d,:] = m1 + rating_train[:,d].T @ phi[:,d,:]\n",
    "        for k in range(K):\n",
    "            lambda_rate[d,k] = tau_shape/tau_rate[d] + np.sum([gamma_shape[u,k]/gamma_rate[u,k] for u in bycol[d]])\n",
    "        tau_rate[d] = m0/n0 + np.sum([lambda_shape[d,k]/lambda_rate[d,k] for k in range(K)])\n",
    "\n",
    "    time3 = time.time()\n",
    "    print(f'Time update phi: {time1 - time0}, Time update gamma and kappa: {time2 - time1}, Time update lambda and tau: {time3 - time2}')\n",
    "\n",
    "    #Validate\n",
    "    theta, beta = gamma_shape/gamma_rate, lambda_shape/lambda_rate\n",
    "    training_likelihood = validate(theta, beta, rating_train)\n",
    "    val_likelihood = validate(theta, beta, rating_valid)\n",
    "    print(f'Iter {n_iter}: training_error = {training_likelihood}, val_error = {val_likelihood}, max_pref = {np.sum(theta,0).max()}, min_pref = {np.sum(theta,0).min()},max_att = {np.sum(beta,0).max()}, min_att = {np.sum(beta,0).min()}')\n",
    "    if n_iter > 0:\n",
    "        if abs(val_likelihood/last_val_likelihood-1) < threshold or n_iter >= max_iter:\n",
    "            print(f'Compete after {n_iter} iterations: Validation Error = {val_likelihood}')\n",
    "            break\n",
    "    last_val_likelihood = val_likelihood\n",
    "    n_iter += 1 \n",
    "np.savez(r'C:\\git\\PGM\\temp.npz', theta = theta, beta = beta)\n",
    "return theta, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cavi():\n",
    "    pass\n",
    "\n",
    "def sgd():\n",
    "    pass\n",
    "\n",
    "def natural_gradient():\n",
    "    pass\n",
    "\n",
    "def using_edward():\n",
    "    pass\n",
    "\n",
    "def using_pystan():\n",
    "    pass\n",
    "\n",
    "def vae():\n",
    "    pass\n",
    "\n",
    "def advi():\n",
    "    pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    rating_train, rating_valid, rating_test, movie_map = read()\n",
    "    #rating = np.array([[random.poisson(3) for i in range(2000)] for j in range(100)])\n",
    "    gibbs(rating_valid, rating_valid,max_iter = 50 )\n",
    "    \n",
    "    # model = vi(rating_valid, rating_valid, max_iter = 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
